{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.导入包并设置GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#设置LOG信息显示等级\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "os.environ['CUDA_VISIABLE_DEVICES']='O'\n",
    "\n",
    "import tensorflow as tf \n",
    "print(tf.__version__)\n",
    "\n",
    "phy_gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in phy_gpus:\n",
    "    #设置GPU按需申请显存\n",
    "    tf.config.experimental.set_memory_growth(gpu,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.加法运算与广播机制\n",
    "* 直接使用'+'时两个元素至少有一个得是Tensor\n",
    "* 使用tf.math.add( x, y, name=None)会自动将元素转换为Tensor\n",
    "* 当两个元素中有一个元素为一个值，另一个元素包含多个值时会自动应用广播机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([6 7 8], shape=(3,), dtype=int32)\n",
      "tf.Tensor([6 7 8], shape=(3,), dtype=int32)\n",
      "tf.Tensor([6 7 8], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#直接使用'+'\n",
    "print(tf.constant([1,2,3])+5)\n",
    "\n",
    "#使用tf.add()\n",
    "print(tf.math.add([1,2,3],5))\n",
    "print(tf.math.add(tf.constant([1,2,3]),5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.矩阵乘法和向量乘法\n",
    "要分清楚自己要的是向量乘法还是矩阵乘法。\n",
    "\n",
    "* 矩阵乘法（线性代数里的矩阵乘法）:tf.matmul()\n",
    "* 向量乘法（对应位置元素相乘）:tf.Tensor * tf.Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7 10]\n",
      " [15 22]]\n",
      "--------\n",
      "[ 5 12 21 32]\n"
     ]
    }
   ],
   "source": [
    "# 矩阵乘法：\n",
    "a = tf.constant([[1,2],[3,4]])\n",
    "b = tf.constant([[1,2],[3,4]])\n",
    "c = tf.matmul(a,b)\n",
    "print(c.numpy())\n",
    "\n",
    "print(\"--------\")\n",
    "\n",
    "# 向量乘法\n",
    "e = tf.constant([1,2,3,4])\n",
    "f = tf.constant([5,6,7,8])\n",
    "d = e*f\n",
    "print(d.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.取绝对值和取整\n",
    "* 取绝对值：tf.math.abs(x, name=None)\n",
    "* 向下取整：tf.math.floor(x, name=None)\n",
    "* 向上取整：tf.math.ceil(x, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([10 20 99], shape=(3,), dtype=int32)\n",
      "tf.Tensor([3. 5. 7.], shape=(3,), dtype=float32)\n",
      "tf.Tensor([4. 6. 8.], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.math.abs([-10,-20,-99]))\n",
    "print(tf.math.floor([3.14,5.5,7.8]))\n",
    "print(tf.math.ceil([3.14,5.5,7.8]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.方差\n",
    "* 方差：tf.math.squared_difference(x, y, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 0  4 16 36 64], shape=(5,), dtype=int32) <class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    }
   ],
   "source": [
    "#方差\n",
    "x = np.array([1,3,5,7,9])\n",
    "y = np.array([1,1,1,1,1])  #shape of y:(5,)\n",
    "s = tf.math.squared_difference(x,y)\n",
    "print(s,type(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 0  4 16 36 64], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#可以广播\n",
    "y1 = 1\n",
    "s1 = tf.math.squared_difference(x,y1)\n",
    "print(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0  4 16 36 64]\n",
      " [ 0  4 16 36 64]\n",
      " [ 0  4 16 36 64]\n",
      " [ 0  4 16 36 64]\n",
      " [ 0  4 16 36 64]], shape=(5, 5), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# x是一维的，y2是二维的，y2中每一个元素都进行了一次广播\n",
    "y2 = np.array([[1],[1],[1],[1],[1]]) #shape of y2:(5,1)\n",
    "s2 = tf.math.squared_difference(x,y2)\n",
    "print(s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.均值\n",
    "\n",
    "均值叫reduce_mean而非mean，是因为均值是一个值，所以这个过程往往对输入进行了降维。\n",
    "* 均值：tf.math.reduce_mean(input_tensor, axis=None, keepdims=False, name=None)\n",
    "* keepdims=True 保证输入和输出Tensor的维度相同\n",
    "* axis = None：所有元素的平均值\n",
    "* axis = 0:竖轴平均值\n",
    "* axis = 1:横轴平均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[3]], shape=(1, 1), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#m是二维的，输出mean也是二维的\n",
    "m = np.array([[2,2],[4,4]])\n",
    "mean = tf.math.reduce_mean(m,keepdims=True)\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2. 3.], shape=(2,), dtype=float64)\n",
      "tf.Tensor([1.5 3.5], shape=(2,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "#[[1.,2.], 1.5\n",
    "# [3.,4.]] 3.5\n",
    "#  2. 3.\n",
    "m = np.array([[1.,2.],[3.,4.]])\n",
    "mean_0 = tf.math.reduce_mean(m,axis=0)\n",
    "mean_1 = tf.math.reduce_mean(m,axis=1)\n",
    "print(mean_0)\n",
    "print(mean_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.随机数生成\n",
    "* 正态分布：tf.random.normal(shape,mean=0.0,stddev=1.0,dtype=tf.dtypes.float32,seed=None,name=None)\n",
    "* 均匀分布(左闭右开)：tf.random.uniform(shape,minval=0,maxval=None,dtype=tf.dtypes.float32,seed=None,name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.7671541  -0.44922647]\n",
      " [-0.23749553 -2.9399974 ]\n",
      " [-1.989044   -1.7925733 ]], shape=(3, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[9 1 6 7]\n",
      " [3 7 4 5]], shape=(2, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 正态分布\n",
    "rand1 = tf.random.normal(shape=(3,2),mean=0.0,stddev=2.0)\n",
    "print(rand1)\n",
    "\n",
    "# 均匀分布\n",
    "rand2 = tf.random.uniform(shape=(2,4),minval=1,maxval=10,dtype=tf.int32)\n",
    "print(rand2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.寻找极值\n",
    "返回要寻找极值的索引，也是一个Tensor：\n",
    "* 极大值：tf.math.argmax(input, axis=None, output_type=tf.dtypes.int64, name=None)\n",
    "* 极小值：tf.math.argmin(input, axis=None, output_type=tf.dtypes.int64, name=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(6, shape=(), dtype=int64)\n",
      "tf.Tensor(5, shape=(), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensorflow.python.framework.ops.EagerTensor,\n",
       " tensorflow.python.framework.ops.EagerTensor)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array([1,3,5,2,11,0,99])\n",
    "\n",
    "# 极大值索引\n",
    "d = tf.math.argmax(data)\n",
    "print(d)\n",
    "\n",
    "# 极小值索引\n",
    "e = tf.math.argmin(data)\n",
    "print(e)\n",
    "\n",
    "type(d),type(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 0 1], shape=(3,), dtype=int64)\n",
      "tf.Tensor([1 2], shape=(2,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "data = np.array([[1,6,3],[4,5,6]])\n",
    "\n",
    "#data\n",
    "#[[1,6,3],  1\n",
    "# [4,5,6]]  2\n",
    "#  1 0 1\n",
    "d_0 = tf.math.argmax(data,axis=0)\n",
    "d_1 = tf.math.argmax(data,axis=1)\n",
    "print(d_0)\n",
    "print(d_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
